{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scGNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbXaOkVkwYjAtgjgGr3+9J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inoue0426/scRNA-Data-Imputation-comparison/blob/main/notebooks/scGNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPzk-JTijy0f",
        "outputId": "b6552e99-6a47-406f-eb2d-9634fd21e4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'scGNN'...\n",
            "remote: Enumerating objects: 5617, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 5617 (delta 70), reused 84 (delta 35), pack-reused 5481\u001b[K\n",
            "Receiving objects: 100% (5617/5617), 70.08 MiB | 21.67 MiB/s, done.\n",
            "Resolving deltas: 100% (4273/4273), done.\n",
            "Collecting numpy==1.18.1\n",
            "  Downloading numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting torch==1.2.0\n",
            "  Downloading torch-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (748.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9 MB 700 bytes/s \n",
            "\u001b[?25hCollecting networkx==2.4\n",
            "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 34.6 MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 34.1 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.1.2\n",
            "  Downloading matplotlib-3.1.2-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting seaborn==0.9.0\n",
            "  Downloading seaborn-0.9.0-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 39.5 MB/s \n",
            "\u001b[?25hCollecting umap-learn==0.3.10\n",
            "  Downloading umap-learn-0.3.10.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting munkres==1.1.2\n",
            "  Downloading munkres-1.1.2-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting tqdm==4.48.0\n",
            "  Downloading tqdm-4.48.0-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting python-igraph==0.8.3\n",
            "  Downloading python_igraph-0.8.3-cp37-cp37m-manylinux2010_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx==2.4->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 5)) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.2->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.9.0->-r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10->-r requirements.txt (line 7)) (1.0.2)\n",
            "Requirement already satisfied: numba>=0.37 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10->-r requirements.txt (line 7)) (0.51.2)\n",
            "Collecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.1.2->-r requirements.txt (line 5)) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.37->umap-learn==0.3.10->-r requirements.txt (line 7)) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.37->umap-learn==0.3.10->-r requirements.txt (line 7)) (0.34.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.3->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->umap-learn==0.3.10->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->umap-learn==0.3.10->-r requirements.txt (line 7)) (3.1.0)\n",
            "Building wheels for collected packages: umap-learn\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.3.10-py3-none-any.whl size=38881 sha256=1858412a09fe7c42584f0eb86a7973dda4b33e86fa1355a3c9c7e027aac9f680\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/d0/8f/9e64bfc5ed0645f89b639196bef92daf5c704285133efce12f\n",
            "Successfully built umap-learn\n",
            "Installing collected packages: numpy, texttable, pandas, matplotlib, umap-learn, tqdm, torch, seaborn, python-igraph, networkx, munkres\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.63.0\n",
            "    Uninstalling tqdm-4.63.0:\n",
            "      Successfully uninstalled tqdm-4.63.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.11.2\n",
            "    Uninstalling seaborn-0.11.2:\n",
            "      Successfully uninstalled seaborn-0.11.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.2.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.2.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.2.0 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.18.1 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.1 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.1 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.1 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.1.2 munkres-1.1.2 networkx-2.4 numpy-1.18.1 pandas-0.25.3 python-igraph-0.8.3 seaborn-0.9.0 texttable-1.6.4 torch-1.2.0 tqdm-4.48.0 umap-learn-0.3.10\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/juexinwang/scGNN.git\n",
        "!cd scGNN && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir GSE138852\n",
        "!wget -P GSE138852/ https://ftp.ncbi.nlm.nih.gov/geo/series/GSE138nnn/GSE138852/suppl/GSE138852_counts.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDfbp1yIkC7V",
        "outputId": "cc7d0af7-866b-474a-aea8-ba3d8ace4b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-03 18:06:31--  https://ftp.ncbi.nlm.nih.gov/geo/series/GSE138nnn/GSE138852/suppl/GSE138852_counts.csv.gz\n",
            "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 165.112.9.229, 130.14.250.13, 2607:f220:41e:250::11, ...\n",
            "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|165.112.9.229|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12466052 (12M) [application/x-gzip]\n",
            "Saving to: ‘GSE138852/GSE138852_counts.csv.gz’\n",
            "\n",
            "GSE138852_counts.cs 100%[===================>]  11.89M  33.7MB/s    in 0.4s    \n",
            "\n",
            "2022-04-03 18:06:32 (33.7 MB/s) - ‘GSE138852/GSE138852_counts.csv.gz’ saved [12466052/12466052]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -W ignore scGNN/PreprocessingscGNN.py \\\n",
        "            --datasetName GSE138852_counts.csv.gz \\\n",
        "            --datasetDir GSE138852/ \\\n",
        "            --LTMGDir GSE138852/ \\\n",
        "            --filetype CSV \\\n",
        "            --geneSelectnum 2000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4omWSsQkMX8",
        "outputId": "3d72c056-e2e6-453f-f78a-4786e896ae9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step1: Start filter and generating CSV\n",
            "Input scRNA data in CSV format is validated, start reading...\n",
            "tcmalloc: large alloc 1146978304 bytes == 0x55f738df6000 @  0x7f3a168e81e7 0x7f3a143ce631 0x7f3a14432ed8 0x7f3a14433197 0x7f3a144cb148 0x55f6e50651f4 0x55f6e5064ef0 0x55f6e50d964d 0x55f6e50667aa 0x55f6e50d48f6 0x55f6e50d3a2e 0x55f6e506688a 0x55f6e50d48f6 0x55f6e50667aa 0x55f6e50d48f6 0x55f6e50667aa 0x55f6e50d48f6 0x55f6e50d3a2e 0x55f6e506688a 0x55f6e50d5719 0x55f6e50d3cdd 0x55f6e506688a 0x55f6e50d5719 0x55f6e50d3cdd 0x55f6e506713c 0x55f6e50a8239 0x55f6e50a5184 0x55f6e50659f9 0x55f6e50d9937 0x55f6e50d3a2e 0x55f6e506688a\n",
            "Data loaded, start filtering...\n",
            "After preprocessing, 10312 genes remaining\n",
            "After preprocessing, 13214 cells have 0.99 nonzero\n",
            "Preprocessing Done. Total Running Time: 84.46953797340393 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -W ignore scGNN/scGNN.py --datasetName GSE138852 \\\n",
        "                      --datasetDir ./  \\\n",
        "                      --outputDir outputdir/ \\\n",
        "                      --EM-iteration 2 \\\n",
        "                      --Regu-epochs 50 \\\n",
        "                      --EM-epochs 20 \\\n",
        "                      --quickmode \\\n",
        "                      --nonsparseMode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xkhPQnIk63s",
        "outputId": "abc65043-2ab2-4101-feda-b5585d7d67ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:cuda\n",
            "---0:00:00---scRNA starts loading.\n",
            "Load expression in csv format\n",
            "---0:00:11---scRNA has been successfully loaded\n",
            "---0:00:11---TrainLoader has been successfully prepared.\n",
            "---0:00:12---Pytorch model ready.\n",
            "Start training...\n",
            "Train Epoch: 1 [0/13214 (0%)]\tLoss: 35.965430\n",
            "====> Epoch: 1 Average loss: 38.3628\n",
            "Train Epoch: 2 [0/13214 (0%)]\tLoss: 33.668225\n",
            "====> Epoch: 2 Average loss: 35.9635\n",
            "Train Epoch: 3 [0/13214 (0%)]\tLoss: 32.449316\n",
            "====> Epoch: 3 Average loss: 34.6583\n",
            "Train Epoch: 4 [0/13214 (0%)]\tLoss: 30.429307\n",
            "====> Epoch: 4 Average loss: 32.5715\n",
            "Train Epoch: 5 [0/13214 (0%)]\tLoss: 30.313120\n",
            "====> Epoch: 5 Average loss: 32.3444\n",
            "Train Epoch: 6 [0/13214 (0%)]\tLoss: 27.904065\n",
            "====> Epoch: 6 Average loss: 29.8993\n",
            "Train Epoch: 7 [0/13214 (0%)]\tLoss: 27.580176\n",
            "====> Epoch: 7 Average loss: 29.4889\n",
            "Train Epoch: 8 [0/13214 (0%)]\tLoss: 26.903328\n",
            "====> Epoch: 8 Average loss: 28.7428\n",
            "Train Epoch: 9 [0/13214 (0%)]\tLoss: 26.562817\n",
            "====> Epoch: 9 Average loss: 28.3290\n",
            "Train Epoch: 10 [0/13214 (0%)]\tLoss: 25.836824\n",
            "====> Epoch: 10 Average loss: 27.5428\n",
            "Train Epoch: 11 [0/13214 (0%)]\tLoss: 25.285913\n",
            "====> Epoch: 11 Average loss: 26.9373\n",
            "Train Epoch: 12 [0/13214 (0%)]\tLoss: 24.805134\n",
            "====> Epoch: 12 Average loss: 26.4066\n",
            "Train Epoch: 13 [0/13214 (0%)]\tLoss: 24.272236\n",
            "====> Epoch: 13 Average loss: 25.8314\n",
            "Train Epoch: 14 [0/13214 (0%)]\tLoss: 23.731794\n",
            "====> Epoch: 14 Average loss: 25.2534\n",
            "Train Epoch: 15 [0/13214 (0%)]\tLoss: 23.247388\n",
            "====> Epoch: 15 Average loss: 24.7357\n",
            "Train Epoch: 16 [0/13214 (0%)]\tLoss: 22.892271\n",
            "====> Epoch: 16 Average loss: 24.3467\n",
            "Train Epoch: 17 [0/13214 (0%)]\tLoss: 22.561060\n",
            "====> Epoch: 17 Average loss: 23.9838\n",
            "Train Epoch: 18 [0/13214 (0%)]\tLoss: 22.228113\n",
            "====> Epoch: 18 Average loss: 23.6228\n",
            "Train Epoch: 19 [0/13214 (0%)]\tLoss: 21.913608\n",
            "====> Epoch: 19 Average loss: 23.2833\n",
            "Train Epoch: 20 [0/13214 (0%)]\tLoss: 21.605298\n",
            "====> Epoch: 20 Average loss: 22.9531\n",
            "Train Epoch: 21 [0/13214 (0%)]\tLoss: 21.298015\n",
            "====> Epoch: 21 Average loss: 22.6276\n",
            "Train Epoch: 22 [0/13214 (0%)]\tLoss: 20.984387\n",
            "====> Epoch: 22 Average loss: 22.2990\n",
            "Train Epoch: 23 [0/13214 (0%)]\tLoss: 20.757610\n",
            "====> Epoch: 23 Average loss: 22.0576\n",
            "Train Epoch: 24 [0/13214 (0%)]\tLoss: 20.574783\n",
            "====> Epoch: 24 Average loss: 21.8586\n",
            "Train Epoch: 25 [0/13214 (0%)]\tLoss: 20.447020\n",
            "====> Epoch: 25 Average loss: 21.7127\n",
            "Train Epoch: 26 [0/13214 (0%)]\tLoss: 20.337504\n",
            "====> Epoch: 26 Average loss: 21.5841\n",
            "Train Epoch: 27 [0/13214 (0%)]\tLoss: 20.231847\n",
            "====> Epoch: 27 Average loss: 21.4592\n",
            "Train Epoch: 28 [0/13214 (0%)]\tLoss: 20.137137\n",
            "====> Epoch: 28 Average loss: 21.3454\n",
            "Train Epoch: 29 [0/13214 (0%)]\tLoss: 20.050326\n",
            "====> Epoch: 29 Average loss: 21.2397\n",
            "Train Epoch: 30 [0/13214 (0%)]\tLoss: 19.969017\n",
            "====> Epoch: 30 Average loss: 21.1403\n",
            "Train Epoch: 31 [0/13214 (0%)]\tLoss: 19.916191\n",
            "====> Epoch: 31 Average loss: 21.0698\n",
            "Train Epoch: 32 [0/13214 (0%)]\tLoss: 19.941790\n",
            "====> Epoch: 32 Average loss: 21.0755\n",
            "Train Epoch: 33 [0/13214 (0%)]\tLoss: 20.038318\n",
            "====> Epoch: 33 Average loss: 21.1525\n",
            "Train Epoch: 34 [0/13214 (0%)]\tLoss: 19.790488\n",
            "====> Epoch: 34 Average loss: 20.8991\n",
            "Train Epoch: 35 [0/13214 (0%)]\tLoss: 19.754905\n",
            "====> Epoch: 35 Average loss: 20.8473\n",
            "Train Epoch: 36 [0/13214 (0%)]\tLoss: 19.703867\n",
            "====> Epoch: 36 Average loss: 20.7824\n",
            "Train Epoch: 37 [0/13214 (0%)]\tLoss: 19.604415\n",
            "====> Epoch: 37 Average loss: 20.6705\n",
            "Train Epoch: 38 [0/13214 (0%)]\tLoss: 19.565085\n",
            "====> Epoch: 38 Average loss: 20.6180\n",
            "Train Epoch: 39 [0/13214 (0%)]\tLoss: 19.488876\n",
            "====> Epoch: 39 Average loss: 20.5288\n",
            "Train Epoch: 40 [0/13214 (0%)]\tLoss: 19.454902\n",
            "====> Epoch: 40 Average loss: 20.4817\n",
            "Train Epoch: 41 [0/13214 (0%)]\tLoss: 19.388673\n",
            "====> Epoch: 41 Average loss: 20.4038\n",
            "Train Epoch: 42 [0/13214 (0%)]\tLoss: 19.354625\n",
            "====> Epoch: 42 Average loss: 20.3575\n",
            "Train Epoch: 43 [0/13214 (0%)]\tLoss: 19.302668\n",
            "====> Epoch: 43 Average loss: 20.2941\n",
            "Train Epoch: 44 [0/13214 (0%)]\tLoss: 19.267013\n",
            "====> Epoch: 44 Average loss: 20.2470\n",
            "Train Epoch: 45 [0/13214 (0%)]\tLoss: 19.225599\n",
            "====> Epoch: 45 Average loss: 20.1943\n",
            "Train Epoch: 46 [0/13214 (0%)]\tLoss: 19.191859\n",
            "====> Epoch: 46 Average loss: 20.1494\n",
            "Train Epoch: 47 [0/13214 (0%)]\tLoss: 19.157528\n",
            "====> Epoch: 47 Average loss: 20.1041\n",
            "Train Epoch: 48 [0/13214 (0%)]\tLoss: 19.129371\n",
            "====> Epoch: 48 Average loss: 20.0648\n",
            "Train Epoch: 49 [0/13214 (0%)]\tLoss: 19.094100\n",
            "====> Epoch: 49 Average loss: 20.0189\n",
            "Train Epoch: 50 [0/13214 (0%)]\tLoss: 19.073262\n",
            "====> Epoch: 50 Average loss: 19.9870\n",
            "zOut ready at 38.21946907043457\n",
            "---0:00:38---Start Prune\n",
            "Start pruning 0th cell, cost 6.890296936035156e-05s\n",
            "Start pruning 10000th cell, cost 34.616647243499756s\n",
            "---0:01:23---Prune Finished\n",
            "---0:01:24---EM process starts\n",
            "---0:01:24---Start 0th iteration.\n",
            "tcmalloc: large alloc 1396883456 bytes == 0x556faabde000 @  0x7f63fb4d6001 0x7f63f8e7a7b5 0x7f63f8edee10 0x7f63f8ee0caf 0x7f63f8f77268 0x556f5229d1f4 0x556f5229cef0 0x556f5231164d 0x556f5229e7aa 0x556f52310d30 0x556f5230ba2e 0x556f5229e88a 0x556f5230d719 0x556f5230ba2e 0x556f5229e88a 0x556f52310d30 0x556f5229e7aa 0x556f5230c8f6 0x556f5230ba2e 0x556f5230b723 0x556f523d5812 0x556f523d5b8d 0x556f523d5a36 0x556f523ad183 0x556f523ace2c 0x7f63fa2bec87 0x556f523acd0a\n",
            "tcmalloc: large alloc 1396883456 bytes == 0x557051216000 @  0x7f63fb4d6001 0x7f638152a8bc 0x7f63815202e6 0x7f63814b6d11 0x7f63814b06eb 0x556f5229d1f4 0x556f5229cef0 0x556f5231164d 0x556f5229e7aa 0x556f5230c8f6 0x556f5230ba2e 0x556f5230b723 0x556f523d5812 0x556f523d5b8d 0x556f523d5a36 0x556f523ad183 0x556f523ace2c 0x7f63fa2bec87 0x556f523acd0a\n",
            "Louvain cluster: 25\n",
            "---0:01:54---Clustering Ends\n",
            "Total Cluster Number: 12\n",
            "Train Epoch: 1 [0/13214 (0%)]\tLoss: 19.077061\n",
            "====> Epoch: 1 Average loss: 19.9800\n",
            "Train Epoch: 2 [0/13214 (0%)]\tLoss: 19.126045\n",
            "====> Epoch: 2 Average loss: 20.0166\n",
            "Train Epoch: 3 [0/13214 (0%)]\tLoss: 19.275677\n",
            "====> Epoch: 3 Average loss: 20.1519\n",
            "Train Epoch: 4 [0/13214 (0%)]\tLoss: 19.161512\n",
            "====> Epoch: 4 Average loss: 20.0371\n",
            "Train Epoch: 5 [0/13214 (0%)]\tLoss: 18.994031\n",
            "====> Epoch: 5 Average loss: 19.8611\n",
            "Train Epoch: 6 [0/13214 (0%)]\tLoss: 19.050676\n",
            "====> Epoch: 6 Average loss: 19.9067\n",
            "Train Epoch: 7 [0/13214 (0%)]\tLoss: 18.920787\n",
            "====> Epoch: 7 Average loss: 19.7738\n",
            "Train Epoch: 8 [0/13214 (0%)]\tLoss: 18.939901\n",
            "====> Epoch: 8 Average loss: 19.7819\n",
            "Train Epoch: 9 [0/13214 (0%)]\tLoss: 18.870500\n",
            "====> Epoch: 9 Average loss: 19.7052\n",
            "Train Epoch: 10 [0/13214 (0%)]\tLoss: 18.883416\n",
            "====> Epoch: 10 Average loss: 19.7085\n",
            "Train Epoch: 11 [0/13214 (0%)]\tLoss: 18.851083\n",
            "====> Epoch: 11 Average loss: 19.6694\n",
            "Train Epoch: 12 [0/13214 (0%)]\tLoss: 18.839944\n",
            "====> Epoch: 12 Average loss: 19.6494\n",
            "Train Epoch: 13 [0/13214 (0%)]\tLoss: 18.835303\n",
            "====> Epoch: 13 Average loss: 19.6366\n",
            "Train Epoch: 14 [0/13214 (0%)]\tLoss: 18.779854\n",
            "====> Epoch: 14 Average loss: 19.5743\n",
            "Train Epoch: 15 [0/13214 (0%)]\tLoss: 18.748021\n",
            "====> Epoch: 15 Average loss: 19.5350\n",
            "Train Epoch: 16 [0/13214 (0%)]\tLoss: 18.698300\n",
            "====> Epoch: 16 Average loss: 19.4787\n",
            "Train Epoch: 17 [0/13214 (0%)]\tLoss: 18.695366\n",
            "====> Epoch: 17 Average loss: 19.4674\n",
            "Train Epoch: 18 [0/13214 (0%)]\tLoss: 18.683213\n",
            "====> Epoch: 18 Average loss: 19.4478\n",
            "Train Epoch: 19 [0/13214 (0%)]\tLoss: 18.667532\n",
            "====> Epoch: 19 Average loss: 19.4245\n",
            "Train Epoch: 20 [0/13214 (0%)]\tLoss: 18.668107\n",
            "====> Epoch: 20 Average loss: 19.4173\n",
            "---0:02:10---Start Prune\n",
            "Start pruning 0th cell, cost 9.322166442871094e-05s\n",
            "Start pruning 10000th cell, cost 41.953362464904785s\n",
            "---0:03:05---Prune Finished\n",
            "---0:03:05---Start test converge condition\n",
            "celltype similarity:0.0\n",
            "---0:03:05---0th iteration in EM Finished\n",
            "---0:03:05---Start 1th iteration.\n",
            "tcmalloc: large alloc 1396883456 bytes == 0x557051216000 @  0x7f63fb4d6001 0x7f63f8e7a7b5 0x7f63f8edee10 0x7f63f8ee0caf 0x7f63f8f77268 0x556f5229d1f4 0x556f5229cef0 0x556f5231164d 0x556f5229e7aa 0x556f52310d30 0x556f5230ba2e 0x556f5229e88a 0x556f5230d719 0x556f5230ba2e 0x556f5229e88a 0x556f52310d30 0x556f5229e7aa 0x556f5230c8f6 0x556f5230ba2e 0x556f5230b723 0x556f523d5812 0x556f523d5b8d 0x556f523d5a36 0x556f523ad183 0x556f523ace2c 0x7f63fa2bec87 0x556f523acd0a\n",
            "Louvain cluster: 23\n",
            "---0:03:32---Clustering Ends\n",
            "Total Cluster Number: 11\n",
            "Train Epoch: 1 [0/13214 (0%)]\tLoss: 18.638251\n",
            "====> Epoch: 1 Average loss: 19.3809\n",
            "Train Epoch: 2 [0/13214 (0%)]\tLoss: 18.614105\n",
            "====> Epoch: 2 Average loss: 19.3497\n",
            "Train Epoch: 3 [0/13214 (0%)]\tLoss: 18.586584\n",
            "====> Epoch: 3 Average loss: 19.3159\n",
            "Train Epoch: 4 [0/13214 (0%)]\tLoss: 18.571711\n",
            "====> Epoch: 4 Average loss: 19.2940\n",
            "Train Epoch: 5 [0/13214 (0%)]\tLoss: 18.595259\n",
            "====> Epoch: 5 Average loss: 19.3100\n",
            "Train Epoch: 6 [0/13214 (0%)]\tLoss: 18.608313\n",
            "====> Epoch: 6 Average loss: 19.3159\n",
            "Train Epoch: 7 [0/13214 (0%)]\tLoss: 18.668162\n",
            "====> Epoch: 7 Average loss: 19.3675\n",
            "Train Epoch: 8 [0/13214 (0%)]\tLoss: 18.586460\n",
            "====> Epoch: 8 Average loss: 19.2824\n",
            "Train Epoch: 9 [0/13214 (0%)]\tLoss: 18.571659\n",
            "====> Epoch: 9 Average loss: 19.2614\n",
            "Train Epoch: 10 [0/13214 (0%)]\tLoss: 18.556650\n",
            "====> Epoch: 10 Average loss: 19.2410\n",
            "Train Epoch: 11 [0/13214 (0%)]\tLoss: 18.573413\n",
            "====> Epoch: 11 Average loss: 19.2509\n",
            "Train Epoch: 12 [0/13214 (0%)]\tLoss: 18.498295\n",
            "====> Epoch: 12 Average loss: 19.1728\n",
            "Train Epoch: 13 [0/13214 (0%)]\tLoss: 18.436714\n",
            "====> Epoch: 13 Average loss: 19.1066\n",
            "Train Epoch: 14 [0/13214 (0%)]\tLoss: 18.476794\n",
            "====> Epoch: 14 Average loss: 19.1387\n",
            "Train Epoch: 15 [0/13214 (0%)]\tLoss: 18.452482\n",
            "====> Epoch: 15 Average loss: 19.1092\n",
            "Train Epoch: 16 [0/13214 (0%)]\tLoss: 18.433364\n",
            "====> Epoch: 16 Average loss: 19.0849\n",
            "Train Epoch: 17 [0/13214 (0%)]\tLoss: 18.480906\n",
            "====> Epoch: 17 Average loss: 19.1245\n",
            "Train Epoch: 18 [0/13214 (0%)]\tLoss: 18.550417\n",
            "====> Epoch: 18 Average loss: 19.1863\n",
            "Train Epoch: 19 [0/13214 (0%)]\tLoss: 18.530889\n",
            "====> Epoch: 19 Average loss: 19.1631\n",
            "Train Epoch: 20 [0/13214 (0%)]\tLoss: 18.414021\n",
            "====> Epoch: 20 Average loss: 19.0450\n",
            "---0:03:47---Start Prune\n",
            "Start pruning 0th cell, cost 0.00012350082397460938s\n",
            "Start pruning 10000th cell, cost 47.228981018066406s\n",
            "---0:04:47---Prune Finished\n",
            "---0:04:47---Start test converge condition\n",
            "celltype similarity:0.5858276375824458\n",
            "---0:04:47---1th iteration in EM Finished\n",
            "---0:04:47---Starts Imputation\n",
            "Train Epoch: 1 [0/13214 (0%)]\tLoss: 45600.245000\n",
            "====> Epoch: 1 Average loss: 44300.6857\n",
            "Train Epoch: 2 [0/13214 (0%)]\tLoss: 43353.775000\n",
            "====> Epoch: 2 Average loss: 42118.7587\n",
            "Train Epoch: 3 [0/13214 (0%)]\tLoss: 41379.772500\n",
            "====> Epoch: 3 Average loss: 40206.3472\n",
            "Train Epoch: 4 [0/13214 (0%)]\tLoss: 39372.587500\n",
            "====> Epoch: 4 Average loss: 38256.6439\n",
            "Train Epoch: 5 [0/13214 (0%)]\tLoss: 37451.367500\n",
            "====> Epoch: 5 Average loss: 36393.2208\n",
            "Train Epoch: 6 [0/13214 (0%)]\tLoss: 35727.555000\n",
            "====> Epoch: 6 Average loss: 34719.2220\n",
            "Train Epoch: 7 [0/13214 (0%)]\tLoss: 34316.165000\n",
            "====> Epoch: 7 Average loss: 33349.9423\n",
            "Train Epoch: 8 [0/13214 (0%)]\tLoss: 33581.605000\n",
            "====> Epoch: 8 Average loss: 32636.8679\n",
            "Train Epoch: 9 [0/13214 (0%)]\tLoss: 33004.747500\n",
            "====> Epoch: 9 Average loss: 32076.8773\n",
            "Train Epoch: 10 [0/13214 (0%)]\tLoss: 32332.357500\n",
            "====> Epoch: 10 Average loss: 31423.9751\n",
            "Train Epoch: 11 [0/13214 (0%)]\tLoss: 31590.795000\n",
            "====> Epoch: 11 Average loss: 30704.4888\n",
            "Train Epoch: 12 [0/13214 (0%)]\tLoss: 30984.942500\n",
            "====> Epoch: 12 Average loss: 30116.6438\n",
            "Train Epoch: 13 [0/13214 (0%)]\tLoss: 30486.205000\n",
            "====> Epoch: 13 Average loss: 29632.7816\n",
            "Train Epoch: 14 [0/13214 (0%)]\tLoss: 29997.735000\n",
            "====> Epoch: 14 Average loss: 29159.1897\n",
            "Train Epoch: 15 [0/13214 (0%)]\tLoss: 29631.490000\n",
            "====> Epoch: 15 Average loss: 28804.1247\n",
            "Train Epoch: 16 [0/13214 (0%)]\tLoss: 29334.475000\n",
            "====> Epoch: 16 Average loss: 28515.9307\n",
            "Train Epoch: 17 [0/13214 (0%)]\tLoss: 29074.620000\n",
            "====> Epoch: 17 Average loss: 28263.6536\n",
            "Train Epoch: 18 [0/13214 (0%)]\tLoss: 28809.242500\n",
            "====> Epoch: 18 Average loss: 28005.8937\n",
            "Train Epoch: 19 [0/13214 (0%)]\tLoss: 28536.217500\n",
            "====> Epoch: 19 Average loss: 27740.5590\n",
            "Train Epoch: 20 [0/13214 (0%)]\tLoss: 28253.830000\n",
            "====> Epoch: 20 Average loss: 27466.2526\n",
            "---0:05:31---All iterations finished, start output results.\n",
            "---0:06:06---scGNN finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OJsxnyUik8PG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}